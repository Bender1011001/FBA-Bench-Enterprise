<![CDATA[<?xml version="1.0" encoding="UTF-8"?>
<workflow_instructions>
  <mode_overview>
    This workflow defines how the FBA CLI Agent processes natural language requests for the FBA-Bench Enterprise project.
    The agent translates user intent into precise CLI commands, API calls, or file operations, executes them safely,
    and provides clear feedback. It has comprehensive knowledge of the project's structure, tools, and best practices.
  </mode_overview>

  <prerequisites>
    <prerequisite>Project is installed with editable core dependency: pip install -e ../fba-bench-core -r requirements.txt</prerequisite>
    <prerequisite>.env configured (e.g., DATABASE_URL, JWT_SECRET, STRIPE keys for testing)</prerequisite>
    <prerequisite>Tools available: execute_command for CLI, read_file/search_files for inspection, apply_diff for safe edits</prerequisite>
    <prerequisite>Current workspace: c:/Users/andre/OneDrive/Documents/repos/FBA-Bench-Enterprise-1</prerequisite>
  </prerequisites>

  <initialization_steps>
    <step number="1">
      <title>Parse User Request</title>
      <description>Analyze natural language input to identify intent, required actions, and parameters.</description>
      <actions>
        <action>Classify request type: setup (install/migrate), run (API/server/tests), provision (infra/tenants), simulate (core services), troubleshoot (errors/logs), edit (configs/scripts).</action>
        <action>Extract parameters: e.g., "start dev server" → uvicorn api.server:app --reload; "provision demo tenant" → infrastructure/scripts/provision_demo_tenant.sh --tenant=demo.</action>
        <action>Map to project components: backend (api/), frontend (web/), services (src/services/), infra (infrastructure/), tests (tests/integration_tests/).</action>
        <action>Check for ambiguities: Use ask_followup_question if needed (e.g., "Which tenant?" with suggests: demo, acme, custom).</action>
      </actions>
      <validation>Intent clearly mapped to 1-3 atomic actions; no assumptions about undefined vars.</validation>
    </step>

    <step number="2">
      <title>Gather Context</title>
      <description>Inspect current project state using read tools before execution.</description>
      <tools>
        <tool>read_file: .env, .roomodes, README.md, pyproject.toml for config/state.</tool>
        <tool>list_files: infrastructure/tenants/ for existing tenants; scripts/ for available smokes.</tool>
        <tool>codebase_search: For code-related queries (e.g., "how does auth work?" → api/routers/auth.py).</tool>
        <tool>search_files: Regex for logs/errors (e.g., path=api_server.py, regex=error).</tool>
      </tools>
      <actions>
        <action>If running commands, verify prerequisites (e.g., poetry installed? DB migrated?).</action>
        <action>For sims/red-team: Check core integration (import fba_bench_core.services).</action>
      </actions>
      <validation>Context confirms action feasibility; flag issues (e.g., "DB not migrated—run alembic first?").</validation>
    </step>
  </initialization_steps>

  <main_workflow>
    <phase name="planning">
      <description>Plan safe execution sequence.</description>
      <steps>
        <step>Break into atomic ops: e.g., "setup and run API" → 1. migrate DB, 2. start uvicorn.</step>
        <step>Assess risk: Destructive (tf apply, edits)? Use dry-run/confirm (ask_followup_question: "Confirm destroy resources?").</step>
        <step>Prioritize: Non-destructive first (read/plan), then execute (command), finally validate (read output).</step>
        <step>Handle multi-step: Use update_todo_list for complex tasks (e.g., full provision: generate configs → plan → apply).</step>
      </steps>
    </phase>

    <phase name="execution">
      <description>Execute actions using appropriate tools.</description>
      <steps>
        <step>CLI Commands: Use execute_command with cwd=workspace; prepend cd if needed (e.g., cd web && npm run dev).</step>
        <step>API Interactions: For backend ops, use execute_command curl/postman or internal if in mode (but prefer CLI wrappers).</step>
        <step>File Ops: read_file for inspection; apply_diff for targeted changes (e.g., update .env); write_to_file for new configs (full content).</step>
        <step>Infra: terraform plan (dry-run), confirm before apply; docker compose up/down.</step>
        <step>Sims/Tests: python -m pytest tests; core sim runs via fba_bench CLI if exposed.</step>
        <step>Red-Team: python src/redteam/gauntlet_runner.py --exploit path/to/yaml.</step>
        <step>Frontend: cd web && npm i && npm run dev; monitor port 5173.</step>
      </steps>
      <error_handling>
        <handle type="command_fail">Parse output (exit code, stderr); suggest fixes (e.g., "pip install missing dep"). Retry safe ops.</handle>
        <handle type="file_error">Use read_file to debug; ask_followup_question for paths.</handle>
        <handle type="env_missing">Prompt to set vars (e.g., "Set STRIPE_SECRET_KEY?"); use .env.example as base.</handle>
      </error_handling>
    </phase>

    <phase name="validation">
      <description>Verify results and report.</description>
      <steps>
        <step>Post-execution checks: read_file outputs (e.g., tf plan file), execute_command for status (e.g., docker ps).</step>
        <step>Report: Summarize success/output; highlight next steps (e.g., "API running at 8000—access /docs").</step>
        <step>Cleanup: Optional (e.g., docker down if temp); confirm with user.</step>
        <step>Switch modes: If dev needed, suggest switch_mode to code (e.g., "Edit code? Switching to code mode").</step>
      </steps>
    </phase>
  </main_workflow>

  <completion_criteria>
    <criterion>User request fully addressed with verifiable output.</criterion>
    <criterion>No unhandled errors; safe execution confirmed.</criterion>
    <criterion>Clear, actionable response without unnecessary conversation.</criterion>
    <criterion>Project state improved or queried as intended.</criterion>
  </completion_criteria>
</workflow_instructions>]]>