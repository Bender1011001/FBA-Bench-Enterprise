<![CDATA[<?xml version="1.0" encoding="UTF-8"?>
<tool_usage_guide>
  <!-- Tool usage guide for FBA-Bench Project Manager mode -->
  <overview>
    This guide details how to use the available tools in this mode. The primary tool is execute_command for running CLI operations. Use ask_followup_question for clarifications, especially for parameterized tasks like experiments. Read and list tools are for gathering context sparingly, as this mode focuses on execution rather than analysis.
  </overview>

  <tool_priorities>
    <priority level="1">
      <tool>ask_followup_question</tool>
      <when>Always use first if user intent is ambiguous or parameters (e.g., config paths) are missing.</when>
      <why>Ensures accurate execution by confirming details, preventing errors in tasks like experiments.</why>
    </priority>
    <priority level="2">
      <tool>execute_command</tool>
      <when>After clarification, for all core tasks: tests, environment management, linting, experiments.</when>
      <why>Directly maps natural language to safe, predefined CLI commands for FBA-Bench operations.</why>
    </priority>
    <priority level="3">
      <tool>read_file or list_files</tool>
      <when>Only if needed for pre-execution checks (e.g., verify config file exists before experiment).</when>
      <why>Provides minimal context without over-relying on file inspection; prefer execution.</why>
    </priority>
  </tool_priorities>

  <tool_specific_guidance>
    <tool name="ask_followup_question">
      <purpose>Gather missing details or confirm actions from the user.</purpose>
      <when_to_use>For experiments (config/output paths), ambiguous requests (e.g., "run tests" vs. specific suite), or destructive actions (e.g., stop env).</when_to_use>
      <syntax>
        <command>ask_followup_question</command>
        <parameters>
          <parameter name="question" required="true">
            <description>A clear, concise question about the missing info.</description>
            <type>string</type>
            <example>What config file for the experiment? (e.g., configs/grok_learning_experiment.yaml)</example>
          </parameter>
          <parameter name="follow_up" required="true">
            <description>2-4 specific, actionable suggestions in <suggest> tags, ordered by priority.</description>
            <type>list of strings</type>
            <example>
              <suggest>configs/grok_learning_experiment.yaml</suggest>
              <suggest>configs/templates/golden_run_baseline.yaml</suggest>
              <suggest>Custom: provide your own path</suggest>
            </example>
          </parameter>
        </parameters>
      </syntax>
      <best_practices>
        <practice>Keep questions specific and suggestions complete (no placeholders).</practice>
        <practice>Limit to 2-4 suggestions to avoid overwhelming the user.</practice>
        <practice>Follow up with execution once clarified.</practice>
      </best_practices>
      <examples>
        <example scenario="experiment config clarification">
          <code><![CDATA[<ask_followup_question>
<question>Which experiment config file should I use? Provide the path.</question>
<follow_up>
<suggest>configs/grok_learning_experiment.yaml (standard learning sim)</suggest>
<suggest>configs/templates/golden_run_baseline.yaml (baseline test)</suggest>
<suggest>Other: configs/my_custom.yaml</suggest>
</follow_up>
</ask_followup_question>]]></code>
          <output>Waits for user response, then proceeds to execute_command with confirmed params.</output>
        </example>
      </examples>
    </tool>

    <tool name="execute_command">
      <purpose>Run CLI commands for FBA-Bench tasks like testing, environment control, linting, and experiments.</purpose>
      <when_to_use>For all execution after clarification; map user requests to predefined safe commands.</when_to_use>
      <syntax>
        <command>execute_command</command>
        <parameters>
          <parameter name="command" required="true">
            <description>The exact CLI command string, using project standards (e.g., poetry run, docker-compose).</description>
            <type>string</type>
            <example>poetry run pytest</example>
          </parameter>
          <parameter name="cwd" optional="true">
            <description>Working directory; default to project root.</description>
            <type>string</type>
            <example>.</example>
          </parameter>
        </parameters>
      </syntax>
      <best_practices>
        <practice>Always use full, tested commands (e.g., include -f for docker-compose files).</practice>
        <practice>Prepend explanations in responses; summarize output post-execution.</practice>
        <practice>For long-running commands (e.g., experiments), inform user of expected duration.</practice>
        <practice>If failure, parse output and suggest fixes without re-executing blindly.</practice>
      </best_practices>
      <examples>
        <example scenario="running tests">
          <code><![CDATA[<execute_command>
<command>poetry run pytest</command>
</execute_command>]]></code>
          <output>Terminal output with test results; summarize passes/failures.</output>
        </example>
        <example scenario="starting dev environment">
          <code><![CDATA[<execute_command>
<command>docker-compose -f docker-compose.dev.yml up --build -d</command>
</execute_command>]]></code>
          <output>Docker logs; confirm services running.</output>
        </example>
        <example scenario="running experiment">
          <code><![CDATA[<execute_command>
<command>poetry run python experiment_cli.py --config-file "configs/grok_learning_experiment.yaml" --output-path "results/my_run"</command>
</execute_command>]]></code>
          <output>Simulation results; save to specified path.</output>
        </example>
      </examples>
    </tool>

    <tool name="read_file">
      <purpose>Read contents of specific files for verification (e.g., check if config exists).</purpose>
      <when_to_use>Sparingly, before executing experiments or if user references a file.</when_to_use>
      <syntax>
        <command>read_file</command>
        <parameters>
          <parameter name="args" required="true">
            <description>One or more <file><path>...</path></file> elements.</description>
            <type>list</type>
            <example><file><path>configs/grok_learning_experiment.yaml</path></file></example>
          </parameter>
        </parameters>
      </syntax>
      <best_practices>
        <practice>Limit to 1-2 files; use only for confirmation, not deep analysis.</practice>
        <practice>If file missing, inform user and suggest alternatives via ask_followup_question.</practice>
      </best_practices>
      <examples>
        <example scenario="verify experiment config">
          <code><![CDATA[<read_file>
<args>
<file>
<path>configs/grok_learning_experiment.yaml</path>
</file>
</args>
</read_file>]]></code>
          <output>Contents if exists; use to confirm before experiment.</output>
        </example>
      </examples>
    </tool>

    <tool name="list_files">
      <purpose>List project files/directories to check structure or existence.</purpose>
      <when_to_use>Before environment commands to confirm docker-compose files, or for config discovery.</when_to_use>
      <syntax>
        <command>list_files</command>
        <parameters>
          <parameter name="path" required="true">
            <description>Directory path relative to workspace.</description>
            <type>string</type>
            <example>.</example>
          </parameter>
          <parameter name="recursive" optional="true">
            <description>true for full tree; false for top-level.</description>
            <type>boolean</type>
            <example>false</example>
          </parameter>
        </parameters>
      </syntax>
      <best_practices>
        <practice>Use non-recursive for quick checks; avoid on large dirs.</practice>
        <practice>Follow up with read_file if a specific file is identified.</practice>
      </best_practices>
      <examples>
        <example scenario="check for compose files">
          <code><![CDATA[<list_files>
<path>.</path>
<recursive>false</recursive>
</list_files>]]></code>
          <output>List including docker-compose*.yml; confirm dev file exists.</output>
        </example>
      </examples>
    </tool>
  </tool_specific_guidance>
</tool_usage_guide>]]>