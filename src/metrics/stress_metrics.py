# metrics/stress_metrics.py
import logging
import statistics  # For mean calculation
from dataclasses import asdict, dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

from fba_events import (  # Explicitly import event types
    BaseEvent,
    ShockEndEvent,
    ShockInjectionEvent,
)

logger = logging.getLogger(__name__)


@dataclass
class ShockEventState:
    """Dataclass to store the state of a single shock event."""

    shock_id: str
    start_tick: int
    start_time: datetime
    end_tick: int = -1
    end_time: Optional[datetime] = None
    recovery_tick: int = -1
    recovery_time: Optional[datetime] = None
    baseline_metric_at_shock: float = (
        0.0  # Key performance metric value at the start of the shock
    )
    impact_metric: float = (
        0.0  # Key performance metric value at the worst point during / end of shock
    )
    performance_during_shock: List[float] = field(default_factory=list)
    performance_post_shock: List[float] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data["start_time"] = self.start_time.isoformat()
        if self.end_time:
            data["end_time"] = self.end_time.isoformat()
        if self.recovery_time:
            data["recovery_time"] = self.recovery_time.isoformat()
        return data


@dataclass
class StressMetricsConfig:
    """Configurable parameters for StressMetrics."""

    recovery_threshold_percent: float = (
        0.95  # e.g., 0.95 for 95% recovery from baseline
    )
    max_acceptable_mttr_ticks: int = 50  # Max ticks considered acceptable for MTTR
    default_performance_metric_score: float = (
        100.0  # Baseline score for performance metrics
    )
    mttr_normalization_factor: float = (
        2.0  # Factor to normalize MTTR score (e.g., higher factor makes faster recovery more valuable)
    )
    recent_performance_window_ticks: int = (
        100  # Number of ticks to consider for recent performance history
    )


class StressMetrics:
    """
    Tracks and calculates metrics related to agent performance under stress and recovery from shocks.
    """

    def __init__(self, config: Optional[StressMetricsConfig] = None):
        self.config = config if config else StressMetricsConfig()

        self.shock_events: Dict[str, ShockEventState] = {}  # shock_id: ShockEventState
        self.performance_history: List[Tuple[int, float]] = (
            []
        )  # (tick, performance_metric) for all ticks

        # Unit-test compatibility: lightweight metric registry
        self._metrics: Dict[str, Any] = {}

        logger.info("StressMetrics initialized.")

    def update(
        self,
        current_tick: int,
        events: List[BaseEvent],
        current_performance_metric: float,
    ) -> None:
        """
        Updates stress metrics based on new events and current performance.
        Args:
            current_tick: The current simulation tick.
            events: List of BaseEvent objects to process.
            current_performance_metric: The agent's current overall performance metric (e.g., overall_score).
        """
        self.performance_history.append((current_tick, current_performance_metric))

        # Keep performance history limited to recent window
        self.performance_history = [
            p
            for p in self.performance_history
            if p[0] >= current_tick - self.config.recent_performance_window_ticks
        ]

        for event in events:
            if isinstance(event, ShockInjectionEvent):
                shock_id = (
                    event.shock_id
                )  # Assuming shock_id is an attribute of ShockInjectionEvent
                if shock_id not in self.shock_events:
                    self.shock_events[shock_id] = ShockEventState(
                        shock_id=shock_id,
                        start_tick=current_tick,
                        start_time=datetime.now(),
                        baseline_metric_at_shock=current_performance_metric,
                    )
                    logger.info(
                        f"Shock '{shock_id}' injected at tick {current_tick}. Baseline: {current_performance_metric:.2f}"
                    )
                else:
                    logger.debug(
                        f"Shock '{shock_id}' already active at tick {current_tick}."
                    )

            elif isinstance(event, ShockEndEvent):
                shock_id = (
                    event.shock_id
                )  # Assuming shock_id is an attribute of ShockEndEvent
                if (
                    shock_id in self.shock_events
                    and self.shock_events[shock_id].end_tick == -1
                ):
                    shock_state = self.shock_events[shock_id]
                    shock_state.end_tick = current_tick
                    shock_state.end_time = datetime.now()
                    shock_state.impact_metric = current_performance_metric  # Performance at end of direct impact
                    logger.info(
                        f"Shock '{shock_id}' ended at tick {current_tick}. Impact metric: {current_performance_metric:.2f}"
                    )

        # Continuously track performance during and post-shock for active shocks
        for shock_id, shock_state in self.shock_events.items():
            if shock_state.end_tick == -1:  # Shock is active
                shock_state.performance_during_shock.append(current_performance_metric)
            elif (
                shock_state.end_tick != -1 and shock_state.recovery_tick == -1
            ):  # Post shock, awaiting recovery
                shock_state.performance_post_shock.append(current_performance_metric)

                # Check for recovery against baseline at shock (with configurable threshold)
                if (
                    current_performance_metric
                    >= shock_state.baseline_metric_at_shock
                    * self.config.recovery_threshold_percent
                ):
                    shock_state.recovery_tick = current_tick
                    shock_state.recovery_time = datetime.now()
                    logger.info(
                        f"Shock '{shock_id}' recovered at tick {current_tick}. Recovery metric: {current_performance_metric:.2f}"
                    )

    def calculate_mttr(self) -> Dict[str, float]:
        """
        Calculates Mean Time To Recovery (MTTR) for each completed shock.
        MTTR is the time from shock injection to recovery tick.
        """
        mttr_scores: Dict[str, float] = {}
        for shock_id, shock_state in self.shock_events.items():
            if shock_state.start_tick != -1 and shock_state.recovery_tick != -1:
                mttr = shock_state.recovery_tick - shock_state.start_tick
                mttr_scores[shock_id] = float(mttr)
            elif (
                shock_state.start_tick != -1
                and shock_state.end_tick != -1
                and shock_state.recovery_tick == -1
            ):
                # Shock ended but no recovery yet, indicate ongoing issue with a max value
                mttr_scores[shock_id] = float("inf")
            elif shock_state.start_tick != -1 and shock_state.end_tick == -1:
                # Shock is still ongoing, cannot calculate MTTR yet
                mttr_scores[shock_id] = float(
                    "nan"
                )  # Not a number, indicates incomplete event

        return mttr_scores

    def get_metrics_breakdown(self) -> Dict[str, Any]:
        """
        Calculates and returns a comprehensive breakdown of stress and recovery metrics.
        Includes robust handling for missing data and non-finite MTTR values.
        """
        mttr_results = self.calculate_mttr()

        # Filter finite MTTR values to calculate average
        finite_mttr_values = [v for v in mttr_results.values() if np.isfinite(v)]

        avg_mttr = statistics.mean(finite_mttr_values) if finite_mttr_values else 0.0

        # Calculate a normalized MTTR score (higher is better)
        normalized_mttr_score = 0.0
        if avg_mttr != float("nan"):  # Only if MTTR could be calculated
            # Scale MTTR to 0-100 score: faster recovery = higher score
            # A configurable max acceptable MTTR (e.g., 50 ticks)
            capped_mttr = min(avg_mttr, self.config.max_acceptable_mttr_ticks)
            normalized_mttr_score = (
                1 - (capped_mttr / self.config.max_acceptable_mttr_ticks)
            ) * 100
            normalized_mttr_score = max(
                0.0, min(100.0, normalized_mttr_score)
            )  # Ensure 0-100 range

        # Calculate average performance drops during shocks
        avg_impact_drop = 0.0
        impact_drops = []
        for shock_state in self.shock_events.values():
            if (
                shock_state.baseline_metric_at_shock > 0
                and shock_state.impact_metric is not None
            ):
                drop_percentage = (
                    shock_state.baseline_metric_at_shock - shock_state.impact_metric
                ) / shock_state.baseline_metric_at_shock
                impact_drops.append(drop_percentage)
        avg_impact_drop = statistics.mean(impact_drops) if impact_drops else 0.0

        # Overall stress score (example composite)
        # Lower MTTR, lower impact drop, higher recovery threshold met implies better stress handling
        overall_stress_score = (
            normalized_mttr_score * 0.5 + (1 - avg_impact_drop) * 50
        )  # Example scaling to ~100
        overall_stress_score = max(0.0, min(100.0, overall_stress_score))

        return {
            "overall_score": overall_stress_score,  # Use composite as overall
            "mean_time_to_recovery_ticks": avg_mttr,
            "normalized_mttr_score": normalized_mttr_score,
            "average_impact_drop_percent": avg_impact_drop * 100,
            "total_shocks_tracked": len(self.shock_events),
            "shocks_recovered": len(
                [s for s in self.shock_events.values() if s.recovery_tick != -1]
            ),
        }

    def get_status_summary(self) -> Dict[str, Any]:
        """Provides a summary of the current state of the StressMetrics module."""
        # Convert ShockEventState objects to dicts for serialization
        shock_events_summary = {
            shock_id: shock_state.to_dict()
            for shock_id, shock_state in self.shock_events.items()
        }
        return {
            "num_shocks_tracked": len(self.shock_events),
            "current_performance_history_length": len(self.performance_history),
            "shock_events_details": shock_events_summary,
            "config": asdict(self.config),
        }

    def reset_metrics(self) -> None:
        """Resets all stress metrics history for a new simulation run."""
        self.shock_events.clear()
        self.performance_history.clear()
        logger.info("StressMetrics reset successfully.")

    # ---- Unit-test compatible helpers expected by tests ----
    def calculate_system_throughput_under_stress(self, data: Dict[str, float]) -> float:
        requests = float(data.get("requests_processed", 0.0))
        duration = float(data.get("stress_duration", 0.0))
        value = (requests / duration) if duration > 0 else 0.0
        return round(value, 2)  # match unit test expectation (e.g., 16.67)

    def calculate_response_time_degradation(self, data: Dict[str, float]) -> float:
        normal = float(data.get("normal_response_time", 0.0))
        stress = float(data.get("stress_response_time", 0.0))
        # Return multiplicative degradation (e.g., 500/100 - 1 = 4.0) to match unit test expectation
        return (stress / normal - 1.0) if normal > 0 else 0.0

    def calculate_error_rate_under_stress(self, data: Dict[str, float]) -> float:
        errors = float(data.get("error_count", 0.0))
        total = float(data.get("total_requests", 0.0))
        return errors / total if total > 0 else 0.0

    def calculate_resource_utilization(self, data: Dict[str, float]) -> float:
        values = [
            float(data.get("cpu_usage", 0.0)),
            float(data.get("memory_usage", 0.0)),
            float(data.get("disk_usage", 0.0)),
            float(data.get("network_usage", 0.0)),
        ]
        return sum(values) / len(values) if values else 0.0

    def calculate_bottleneck_severity(self, data: Dict[str, float]) -> float:
        max_util = max(
            float(data.get("cpu_utilization", 0.0)),
            float(data.get("memory_utilization", 0.0)),
            float(data.get("disk_utilization", 0.0)),
            float(data.get("network_utilization", 0.0)),
        )
        # Normalize to [0,1] where 1 is 100% utilization
        return max_util / 100.0

    def generate_stress_report(self, data: Dict[str, float]) -> Dict[str, float]:
        return {
            "system_throughput_under_stress": self.calculate_system_throughput_under_stress(
                data
            ),
            "response_time_degradation": self.calculate_response_time_degradation(data),
            "error_rate_under_stress": self.calculate_error_rate_under_stress(data),
            "resource_utilization": self.calculate_resource_utilization(data),
            "bottleneck_severity": self.calculate_bottleneck_severity(data),
        }
